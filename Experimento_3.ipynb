{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento 3: HMM varios locutores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import python_speech_features\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', 'words']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sets_file = 'mfcc_sets_BD2.npz'\n",
    "feature_sets = np.load(feature_sets_file)\n",
    "feature_sets.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zero' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight' 'nine'\n",
      " 'yes' 'no' 'up' 'down' 'left' 'right' 'on' 'off' 'stop' 'go']\n"
     ]
    }
   ],
   "source": [
    "words = feature_sets['words']\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70608, 20, 99)\n",
      "(70608,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = feature_sets['x']\n",
    "y = feature_sets['y']\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization, or mean removal and variance scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import preprocessing\n",
    "#for i in range(len(x_train)):\n",
    "    #scaler = preprocessing.StandardScaler().fit(x_train[i])\n",
    "    #x_train[i] = scaler.transform(x_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(x_test)):\n",
    "    #scaler = preprocessing.StandardScaler().fit(x_test[i])\n",
    "    #x_test[i] = scaler.transform(x_test[i])\n",
    "#print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_train)\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files :  56486\n",
      "Test files :  14122\n",
      "y_train\n",
      "[14. 12.  9. ... 15.  0.  4.]\n",
      "y_test\n",
      "[17. 11.  8. ...  4.  4. 15.]\n"
     ]
    }
   ],
   "source": [
    "# Split MFFCC coefficients into random train and test subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(\"Train files : \",len(x_train))\n",
    "print(\"Test files : \", len(x_test))\n",
    "print(\"y_train\")\n",
    "print(y_train)\n",
    "print(\"y_test\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "\n",
    "# Class to handle HMM processing(Python-Machine-Learning-Cookbook)\n",
    "    \n",
    "class HMMTrainer(object):\n",
    "    def __init__(self, model_name='GaussianHMM', n_components=10, cov_type='diag', n_iter=100):\n",
    "        self.model_name = model_name\n",
    "        self.n_components = n_components\n",
    "        self.cov_type = cov_type\n",
    "        self.n_iter = n_iter\n",
    "        self.models = []\n",
    "\n",
    "        if self.model_name == 'GaussianHMM':\n",
    "            self.model = hmm.GaussianHMM(n_components=self.n_components,\n",
    "                    covariance_type=self.cov_type, n_iter=self.n_iter)\n",
    "        else:\n",
    "            raise TypeError('Invalid model type')\n",
    "\n",
    "    # X is a 2D numpy array where each row is 16D\n",
    "    def train(self, X, lengths):\n",
    "        np.seterr(all='ignore')\n",
    "        self.models.append(self.model.fit(X, lengths))#Feature matrix of individual samples.\n",
    "\n",
    "    # Run the model on input data\n",
    "    def get_score(self, input_data, lengths):\n",
    "        return self.model.score(input_data, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un array con todos los MFCC de cada palabra concatenados, para entrenar un modelo HMM por cada palabra\n",
    "X = [np.array([]) for i in range(0, len(words))]\n",
    "lengths = [0 for i in range(0, len(words))]\n",
    "\n",
    "# Iterate through the y_train\n",
    "for i in range(len(y_train)):\n",
    "\n",
    "    # Extract the label\n",
    "    label = int(y_train[i])\n",
    "    \n",
    "    lengths[label] += 1\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfcc_features = x_train[i]\n",
    "            \n",
    "    # Append to the variable X\n",
    "    if len(X[label]) == 0:\n",
    "        X[label] = mfcc_features.T\n",
    "    else:\n",
    "        X[label] = np.append(X[label], mfcc_features.T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3005, 2791, 2804, 2752, 2726, 2971, 2887, 2913, 2732, 2912, 2955, 2810, 2599, 2864, 2788, 2764, 2824, 2764, 2826, 2799]\n"
     ]
    }
   ],
   "source": [
    "print(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train HMM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training word: zero (297495, 20) 3005\n",
      "training word: one (276309, 20) 2791\n",
      "training word: two (277596, 20) 2804\n",
      "training word: three (272448, 20) 2752\n",
      "training word: four (269874, 20) 2726\n",
      "training word: five (294129, 20) 2971\n",
      "training word: six (285813, 20) 2887\n",
      "training word: seven (288387, 20) 2913\n",
      "training word: eight (270468, 20) 2732\n",
      "training word: nine (288288, 20) 2912\n",
      "training word: yes (292545, 20) 2955\n",
      "training word: no (278190, 20) 2810\n",
      "training word: up (257301, 20) 2599\n",
      "training word: down (283536, 20) 2864\n",
      "training word: left (276012, 20) 2788\n",
      "training word: right (273636, 20) 2764\n",
      "training word: on (279576, 20) 2824\n",
      "training word: off (273636, 20) 2764\n",
      "training word: stop (279774, 20) 2826\n",
      "training word: go (277101, 20) 2799\n"
     ]
    }
   ],
   "source": [
    "hmm_models = []# 1 modelo por cada label (palabra)\n",
    "\n",
    "for label in range(len(X)):\n",
    "    word = words[label]\n",
    "    lengths_in = [99 for i in range(0, lengths[label])]\n",
    "    print('training word:', word, X[label].shape, lengths[label])\n",
    "\n",
    "    # Train and save HMM model\n",
    "    hmm_trainer = HMMTrainer()\n",
    "    hmm_trainer.train(X[label], lengths_in)\n",
    "    hmm_models.append((hmm_trainer, label, word))\n",
    "    hmm_trainer = None\n",
    "    lengths_in = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([])\n",
    "# Iterate through the y_test\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "\n",
    "    # Extract the label and view the word\n",
    "    test_label = int(y_test[i])\n",
    "    test_word = words[test_label]\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfcc_features = x_test[i]\n",
    "\n",
    "    # Define variables\n",
    "    max_score = float('-inf')\n",
    "    output_label = None\n",
    "    output_word = word\n",
    "    lengths_in = [99]\n",
    "    \n",
    "    # Iterate through all HMM models and pick\n",
    "    # the one with the highest score\n",
    "    for item in hmm_models:\n",
    "        hmm_model, label, word = item\n",
    "        score = hmm_model.get_score(mfcc_features.T, lengths_in)\n",
    "        #print(score)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            output_label = label\n",
    "            output_word = word\n",
    "            \n",
    "    y_pred = np.append(y_pred, output_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_components=4, n_iter=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[437   7  20  24   5  13  21  21  10  13  20  30   0  35  17  55   2   0\n",
      "   10  12]\n",
      " [ 28 234   5   0  14  30   7   6   0  28   4  81  10 116  27   8  55  11\n",
      "    8  29]\n",
      " [ 68  11 317  28  13  15  36  13  28   3  35  38   2  36  32  11   2   1\n",
      "    1  31]\n",
      " [ 50   2  22 310   1   6  22   9  81  10  42  15   0  28  11  33   1   1\n",
      "    1   6]\n",
      " [ 17  23   3   3 432   8  10   7   0   0  12  22   4  33  13  19  11  29\n",
      "    3  28]\n",
      " [ 24   6   3   8   8 298   8  20   1  28  16  19  46  97  48  48  17  25\n",
      "   27   9]\n",
      " [  9   0  20  15   1   9 361  31  31   2 187   1   3   8  13   4   0   6\n",
      "    8   2]\n",
      " [ 29   6  16   3   3  33  65 363   2  11  68  16   0  50  31  30   2   2\n",
      "   21   5]\n",
      " [ 20   0   5  83   2   5  43   2 407   3  70  14   1  18  11   3   0   2\n",
      "    4   4]\n",
      " [ 19  35   5  10   2  39   7  24   5 317  13  44  10 124  23  20   6   1\n",
      "    2  11]\n",
      " [ 10   3  13   9   3   6 142  34  29   3 403   3   2  22  22  13   1   5\n",
      "    6   8]\n",
      " [ 57  51  15   2  14  18   7  16   0  29   9 234  22  87  26  15  34   7\n",
      "   10  82]\n",
      " [ 25   5   2   1   5  30   6   6   0   3   8  20 330  76  25   4  16  45\n",
      "   45  18]\n",
      " [ 30  56  10   3   0  42  11  23   3  97   8  66  29 215  32  18  34   3\n",
      "   15  21]\n",
      " [ 17   9   6   3   5  47  14  40   8   7  57  22  20  62 293  33   5  24\n",
      "   34   8]\n",
      " [ 58   6  10  25   2  55  17  19   8  22  44  31   3  63  47 245   3   2\n",
      "   10  14]\n",
      " [ 17  76   3   2  12  29   3   2   0  27   5  37  25  83  12   4 252  38\n",
      "   13   8]\n",
      " [ 13  12   1   0  42  27   7   1   1   1   9   5  49  42  10   2  36 367\n",
      "   31   7]\n",
      " [ 30   3   5   0   0  31  10  25   4   1  31   8  30  38  15   7  10  41\n",
      "  439   9]\n",
      " [ 71  50  13   2  39  14   6  12   2   2   8 134  30  63  24  22  11  10\n",
      "    9 157]]\n",
      "Accuracy Score : 45.39725251380825\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        zero       0.42      0.58      0.49       752\n",
      "         one       0.39      0.33      0.36       701\n",
      "         two       0.64      0.44      0.52       721\n",
      "       three       0.58      0.48      0.52       651\n",
      "        four       0.72      0.64      0.67       677\n",
      "        five       0.39      0.39      0.39       756\n",
      "         six       0.45      0.51      0.48       711\n",
      "       seven       0.54      0.48      0.51       756\n",
      "       eight       0.66      0.58      0.62       697\n",
      "        nine       0.52      0.44      0.48       717\n",
      "         yes       0.38      0.55      0.45       737\n",
      "          no       0.28      0.32      0.30       735\n",
      "          up       0.54      0.49      0.51       670\n",
      "        down       0.17      0.30      0.21       716\n",
      "        left       0.40      0.41      0.41       714\n",
      "       right       0.41      0.36      0.38       684\n",
      "          on       0.51      0.39      0.44       648\n",
      "         off       0.59      0.55      0.57       663\n",
      "        stop       0.63      0.60      0.61       737\n",
      "          go       0.33      0.23      0.27       679\n",
      "\n",
      "    accuracy                           0.45     14122\n",
      "   macro avg       0.48      0.45      0.46     14122\n",
      "weighted avg       0.48      0.45      0.46     14122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred)*100 )\n",
    "print('Report : ')\n",
    "print(classification_report(y_test, y_pred, target_names= words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_components=6, n_iter=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[488  13  29  14  10   8  22  18  14  20  10  18   9  16  15  16   1   2\n",
      "    6  23]\n",
      " [  4 290   9   0  15  13   3   8   3  32   1  58  57  57  28   7  56   3\n",
      "   10  47]\n",
      " [ 11  36 397  14   7   6  30  18  44  16   0  10  15  10  23  12   2   1\n",
      "    1  68]\n",
      " [ 14  24  40 381   0   2  20   9  85  11  11   6   6   1   7  20   2   1\n",
      "    0  11]\n",
      " [  1  35   6   0 424   8   9   2   0   5   4  18  24   5  17  16   3  30\n",
      "    2  68]\n",
      " [  3  34   5   2   7 306   8  12   3  30   7   8 113  34  59  36  14  25\n",
      "   24  26]\n",
      " [ 14   2  12  10   0  10 486  46  36   1  39   0   8   4  10  15   0   4\n",
      "    5   9]\n",
      " [ 11   9  13   1   2  10  30 496   5  13  19   6   9  23  51  19   4   2\n",
      "   17  16]\n",
      " [ 14   8  16  87   0   4  51   8 414   6  41   5   9   3  13  11   0   2\n",
      "    1   4]\n",
      " [  2  68   5   3   2  23   3  24   9 344   6  36  27  61  38  20  17   1\n",
      "    8  20]\n",
      " [ 18   7   7   9   0   5 107  33  35   6 428   1   8   5  48  10   1   3\n",
      "    1   5]\n",
      " [  6  99  13   3  15   5   3  18   5  35   3 269  55  30  38  15  18   7\n",
      "    9  89]\n",
      " [  4  54   3   0   5  15   1   4   3   6   0  10 341  10  46   3   9  41\n",
      "   88  27]\n",
      " [  3  91   5   0   5  14   2  22  11  88   4  48  69 184  54  24  29   5\n",
      "   18  40]\n",
      " [  6  28  15   1   4  18  17  27  10  18  37   8  70  18 329  32   6  23\n",
      "   20  27]\n",
      " [ 12  25   9  17   2  21  13  19  29  31   4   5  38  27  49 339   4   5\n",
      "    6  29]\n",
      " [  1 154   3   0  14  11   2   2   2  24   1  26  72  36  13   6 223  29\n",
      "    9  20]\n",
      " [  0  29   2   0  33   8   0   2   3   3   2   6 126   3  10   3  20 357\n",
      "   35  21]\n",
      " [ 11   7   4   0   3  10   4  11   5   2   5   9  79  10  21   3   4  21\n",
      "  490  38]\n",
      " [ 11  62  21   0  29   8   1   6   6   5   1  69  68  18  34  10   7   9\n",
      "   13 301]]\n",
      "Accuracy Score : 51.60033989519898\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        zero       0.77      0.65      0.70       752\n",
      "         one       0.27      0.41      0.33       701\n",
      "         two       0.65      0.55      0.59       721\n",
      "       three       0.70      0.59      0.64       651\n",
      "        four       0.73      0.63      0.68       677\n",
      "        five       0.61      0.40      0.49       756\n",
      "         six       0.60      0.68      0.64       711\n",
      "       seven       0.63      0.66      0.64       756\n",
      "       eight       0.57      0.59      0.58       697\n",
      "        nine       0.49      0.48      0.49       717\n",
      "         yes       0.69      0.58      0.63       737\n",
      "          no       0.44      0.37      0.40       735\n",
      "          up       0.28      0.51      0.36       670\n",
      "        down       0.33      0.26      0.29       716\n",
      "        left       0.36      0.46      0.41       714\n",
      "       right       0.55      0.50      0.52       684\n",
      "          on       0.53      0.34      0.42       648\n",
      "         off       0.63      0.54      0.58       663\n",
      "        stop       0.64      0.66      0.65       737\n",
      "          go       0.34      0.44      0.38       679\n",
      "\n",
      "    accuracy                           0.52     14122\n",
      "   macro avg       0.54      0.52      0.52     14122\n",
      "weighted avg       0.54      0.52      0.52     14122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred)*100 )\n",
    "print('Report : ')\n",
    "print(classification_report(y_test, y_pred, target_names= words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_components=10, n_iter=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[500   9  43  14   9  15  17  10   5  12  16  25   1  12  14  28   2   3\n",
      "   12   5]\n",
      " [  3 305  25   0  22  33   8   5   2  34   4  63  25  25  37   9  52   2\n",
      "   10  37]\n",
      " [ 18  15 465  17  18  17  20  16  15   9   5  19  11   5  17  13   2   1\n",
      "    4  34]\n",
      " [ 26   4  37 416   0  13  13   5  55  18  11  10   5   1  13  18   3   1\n",
      "    2   0]\n",
      " [  7  28  21   2 421  13  14   4   1   2   1  31   8   4  10   8  12  46\n",
      "    5  39]\n",
      " [  3  12  11   3  10 352  15  14   2  39  25  10  62  28  42  45  14  23\n",
      "   37   9]\n",
      " [ 19   1  21   8   3  18 409  40  36   5  99   3   3   1  13  10   2   1\n",
      "   17   2]\n",
      " [  7   6  22   2   1  20  22 484   1   7  62  16   7  14  48  13   5   2\n",
      "   10   7]\n",
      " [  7   0  17  92   2  18  35   2 404  16  49   4   5   0  16  26   0   0\n",
      "    4   0]\n",
      " [  6  31  19  15   6  41   5  13   8 388  17  39  13  27  36  23  18   1\n",
      "    3   8]\n",
      " [ 18   5  13   2   1  13  86  32  38   9 454   4   5   9  23  14   1   2\n",
      "    7   1]\n",
      " [ 10  44  33   1   9  19   9  14   4  22  12 294  22  30  46  17  27   7\n",
      "   11 104]\n",
      " [  4  11  20   0   8  56   5   4   0   7   1  20 328  20  21   5  24  51\n",
      "   64  21]\n",
      " [  9  37  25   4   4  47  10  19   2  49  12  51  26 270  42  28  29   7\n",
      "   16  29]\n",
      " [  6  11  19   3   6  41  15  46   3  21  32  30  35  15 361  22   3   8\n",
      "   26  11]\n",
      " [ 13  15  20  28   9  38  21  10  15  28  24  17  16  20  36 365   0   3\n",
      "    5   1]\n",
      " [  2  55  19   1  13  32   4   1   1  24   5  35  30  42  17   5 291  35\n",
      "   12  24]\n",
      " [  2   3  15   1  46  40   8   1   1   1  11  10  65   7   9   3  35 356\n",
      "   32  17]\n",
      " [ 22   1  14   0  15  41  13   8   0   0  19  12  40   9  14   5   8  20\n",
      "  472  24]\n",
      " [ 19  33  44   0  31  16   2   9   2   8   2 101  20  15  21  15   7  16\n",
      "   15 303]]\n",
      "Accuracy Score : 54.08582353774253\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        zero       0.71      0.66      0.69       752\n",
      "         one       0.49      0.44      0.46       701\n",
      "         two       0.51      0.64      0.57       721\n",
      "       three       0.68      0.64      0.66       651\n",
      "        four       0.66      0.62      0.64       677\n",
      "        five       0.40      0.47      0.43       756\n",
      "         six       0.56      0.58      0.57       711\n",
      "       seven       0.66      0.64      0.65       756\n",
      "       eight       0.68      0.58      0.63       697\n",
      "        nine       0.56      0.54      0.55       717\n",
      "         yes       0.53      0.62      0.57       737\n",
      "          no       0.37      0.40      0.38       735\n",
      "          up       0.45      0.49      0.47       670\n",
      "        down       0.49      0.38      0.43       716\n",
      "        left       0.43      0.51      0.47       714\n",
      "       right       0.54      0.53      0.54       684\n",
      "          on       0.54      0.45      0.49       648\n",
      "         off       0.61      0.54      0.57       663\n",
      "        stop       0.62      0.64      0.63       737\n",
      "          go       0.45      0.45      0.45       679\n",
      "\n",
      "    accuracy                           0.54     14122\n",
      "   macro avg       0.55      0.54      0.54     14122\n",
      "weighted avg       0.55      0.54      0.54     14122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred)*100 )\n",
    "print('Report : ')\n",
    "print(classification_report(y_test, y_pred, target_names= words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
