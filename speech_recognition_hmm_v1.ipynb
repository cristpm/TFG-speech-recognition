{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition using HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import python_speech_features\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_train', 'y_train', 'x_test', 'y_test', 'words']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sets_file = 'mfcc_sets.npz'\n",
    "feature_sets = np.load(feature_sets_file)\n",
    "feature_sets.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes' 'no' 'up' 'down' 'left' 'right' 'on' 'off' 'stop' 'go' 'forward'\n",
      " 'backward']\n"
     ]
    }
   ],
   "source": [
    "words = feature_sets['words']\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25450, 20, 99)\n",
      "(25450,)\n",
      "(12536, 20, 99)\n",
      "(12536,)\n"
     ]
    }
   ],
   "source": [
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization, or mean removal and variance scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.98268157e+00  9.86446075e+00  9.66131497e+00 ...  1.34171584e+01\n",
      "   1.29648415e+01  1.21614665e+01]\n",
      " [-9.81641741e+00 -7.17963250e+00 -8.89570469e+00 ... -3.00880893e+01\n",
      "  -3.00827968e+01 -2.63430335e+01]\n",
      " [-4.21179078e+00  2.76909162e+00 -2.63032587e+00 ...  9.40435391e+00\n",
      "   1.31365694e+01  7.16339859e+00]\n",
      " ...\n",
      " [ 7.62392838e+00 -1.61575584e+00  1.03481596e+00 ...  2.96046042e+00\n",
      "   2.65182215e+00 -3.02095466e+00]\n",
      " [ 4.56104028e+00  5.87183192e-01  1.09039655e+00 ... -9.90274602e-02\n",
      "  -4.52956197e+00 -6.40532541e+00]\n",
      " [ 2.98161635e-02  8.76717745e-01 -2.82792954e+00 ...  7.07371179e-01\n",
      "   2.24843616e+00  1.37236158e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "for i in range(len(x_train)):\n",
    "    scaler = preprocessing.StandardScaler().fit(x_train[i])\n",
    "    x_train[i] = scaler.transform(x_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.34713475  1.53554902  2.33592641 ...  1.0357664   1.17445545\n",
      "   1.32814343]\n",
      " [-1.15834885 -0.94287151 -1.46875671 ... -2.11980029 -2.78226949\n",
      "  -2.20435892]\n",
      " [-0.4491095   0.50379519 -0.18418724 ...  0.7447056   1.19023983\n",
      "   0.86960776]\n",
      " ...\n",
      " [ 1.04864554 -0.1338155   0.56726443 ...  0.27731059  0.22653398\n",
      "  -0.06473113]\n",
      " [ 0.66105134  0.1865189   0.57865993 ...  0.05539672 -0.43354315\n",
      "  -0.37522205]\n",
      " [ 0.08764607  0.22862078 -0.22470125 ...  0.11388724  0.18945674\n",
      "   0.33832306]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12536\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "for i in range(len(x_test)):\n",
    "    scaler = preprocessing.StandardScaler().fit(x_test[i])\n",
    "    x_test[i] = scaler.transform(x_test[i])\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 8. 9. ... 3. 0. 4.]\n",
      "[8. 2. 1. ... 4. 8. 8.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "\n",
    "# Class to handle HMM processing(Python-Machine-Learning-Cookbook)\n",
    "    \n",
    "class HMMTrainer(object):\n",
    "    def __init__(self, model_name='GaussianHMM', n_components=4, cov_type='diag', n_iter=1000):\n",
    "        self.model_name = model_name\n",
    "        self.n_components = n_components\n",
    "        self.cov_type = cov_type\n",
    "        self.n_iter = n_iter\n",
    "        self.models = []\n",
    "\n",
    "        if self.model_name == 'GaussianHMM':\n",
    "            self.model = hmm.GaussianHMM(n_components=self.n_components,\n",
    "                    covariance_type=self.cov_type, n_iter=self.n_iter)\n",
    "        else:\n",
    "            raise TypeError('Invalid model type')\n",
    "\n",
    "    # X is a 2D numpy array where each row is 16D\n",
    "    def train(self, X, lengths):\n",
    "        np.seterr(all='ignore')\n",
    "        self.models.append(self.model.fit(X, lengths))#Feature matrix of individual samples.\n",
    "\n",
    "    # Run the model on input data\n",
    "    def get_score(self, input_data, lengths):\n",
    "        return self.model.score(input_data, lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train HMM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.array([]) for i in range(0, len(words))]\n",
    "lengths = [0 for i in range(0, len(words))]\n",
    "\n",
    "# Iterate through the y_train\n",
    "for i in range(len(y_train)):\n",
    "\n",
    "    # Extract the label\n",
    "    label = int(y_train[i])\n",
    "    \n",
    "    lengths[label] += 1\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfcc_features = x_train[i]\n",
    "            \n",
    "    # Append to the variable X\n",
    "    if len(X[label]) == 0:\n",
    "        X[label] = mfcc_features.T\n",
    "    else:\n",
    "        X[label] = np.append(X[label], mfcc_features.T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2457, 2359, 2156, 2402, 2417, 2285, 2361, 2290, 2393, 2334, 965, 1031]\n"
     ]
    }
   ],
   "source": [
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training word: yes (243243, 20) 2457\n",
      "training word: no (233541, 20) 2359\n",
      "training word: up (213444, 20) 2156\n",
      "training word: down (237798, 20) 2402\n",
      "training word: left (239283, 20) 2417\n",
      "training word: right (226215, 20) 2285\n",
      "training word: on (233739, 20) 2361\n",
      "training word: off (226710, 20) 2290\n",
      "training word: stop (236907, 20) 2393\n",
      "training word: go (231066, 20) 2334\n",
      "training word: forward (95535, 20) 965\n",
      "training word: backward (102069, 20) 1031\n"
     ]
    }
   ],
   "source": [
    "hmm_models = []# 1 modelo por cada label (palabra)\n",
    "\n",
    "for label in range(len(X)):\n",
    "    word = words[label]\n",
    "    lengths_in = [99 for i in range(0, lengths[label])]\n",
    "    print('training word:', word, X[label].shape, lengths[label])\n",
    "\n",
    "    # Train and save HMM model\n",
    "    hmm_trainer = HMMTrainer()\n",
    "    hmm_trainer.train(X[label], lengths_in)\n",
    "    hmm_models.append((hmm_trainer, label, word))\n",
    "    hmm_trainer = None\n",
    "    lengths_in = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([])\n",
    "# Iterate through the y_test\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "\n",
    "    # Extract the label and view the word\n",
    "    test_label = int(y_test[i])\n",
    "    test_word = words[test_label]\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfcc_features = x_test[i]\n",
    "\n",
    "    # Define variables\n",
    "    max_score = float('-inf')\n",
    "    output_label = None\n",
    "    output_word = word\n",
    "    lengths_in = [99]\n",
    "    \n",
    "    # Iterate through all HMM models and pick\n",
    "    # the one with the highest score\n",
    "    for item in hmm_models:\n",
    "        hmm_model, label, word = item\n",
    "        score = hmm_model.get_score(mfcc_features.T, lengths_in)\n",
    "        #print(score)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            output_label = label\n",
    "            output_word = word\n",
    "            \n",
    "    y_pred = np.append(y_pred, output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[870   9   2  53 108  95   8   3  64  10   3  10]\n",
      " [ 18 451  28 177  63  59  94  13  11 176  27  69]\n",
      " [  1  69 567 123  66  13  40  65  87  31   6  45]\n",
      " [  7 176  40 440  82  95 131   8  31  55   5 108]\n",
      " [ 84  43  49  99 523  92  26  29  56  23   8  53]\n",
      " [ 54  60  13 149 122 519  14   6  25  51  23 127]\n",
      " [  2 131  77 177  30  20 506  61  19  29  27  32]\n",
      " [  9  29 106  66  42   6  73 645  74  20  55  12]\n",
      " [ 56  10  57  64  54  35  23  85 739  16  20  11]\n",
      " [ 11 243  45 129  59  69  50  34  21 297 102  84]\n",
      " [  2  19   5  13  10  10  15  11   2  35 333  32]\n",
      " [  5  36   9  47  30  52  12   3   4  21  22 286]]\n",
      "Accuracy Score : 49.266113592852584\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.78      0.70      0.74      1235\n",
      "          no       0.35      0.38      0.37      1186\n",
      "          up       0.57      0.51      0.54      1113\n",
      "        down       0.29      0.37      0.32      1178\n",
      "        left       0.44      0.48      0.46      1085\n",
      "       right       0.49      0.45      0.47      1163\n",
      "          on       0.51      0.46      0.48      1111\n",
      "         off       0.67      0.57      0.61      1137\n",
      "        stop       0.65      0.63      0.64      1170\n",
      "          go       0.39      0.26      0.31      1144\n",
      "     forward       0.53      0.68      0.60       487\n",
      "    backward       0.33      0.54      0.41       527\n",
      "\n",
      "    accuracy                           0.49     12536\n",
      "   macro avg       0.50      0.50      0.50     12536\n",
      "weighted avg       0.51      0.49      0.50     12536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(y_test, y_pred)*100 )\n",
    "print('Report : ')\n",
    "print(classification_report(y_test, y_pred, target_names= words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
